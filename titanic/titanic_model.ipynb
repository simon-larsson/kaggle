{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removes a warning in sklearn that will be fixed during an update mid 2018\n",
    "import warnings\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "    le = sk.preprocessing.LabelEncoder()\n",
    "    le.fit([1, 2, 2, 6])\n",
    "    le.transform([1, 1, 2, 6])\n",
    "    le.inverse_transform([0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/GitHub/kaggle/titanic/data/train.csv', sep=',', header=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def substrings_in_string(whole, subs): \n",
    "    \n",
    "    for x in subs:\n",
    "        if x in str(whole): \n",
    "            return x\n",
    "        \n",
    "    return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_title(full_name):\n",
    "    \n",
    "    full_name  = str(full_name)\n",
    "    \n",
    "    x = full_name.split(\", \")\n",
    "    x = x[1]\n",
    "    x = x.split('.')\n",
    "    x = x[0]\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_titles(x):\n",
    "    \n",
    "    title=x['Title']\n",
    "    \n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Dona', 'Lady']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title == 'Dr':\n",
    "        if x['Sex'] == 0:\n",
    "            return 'Mrs'\n",
    "        else:\n",
    "            return 'Mr'\n",
    "    else:\n",
    "        return title\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df, prediction_data=False, print_info=False):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    \n",
    "    Performs preprocessing on the titanic data\n",
    "    \n",
    "    PassengerId - Id (Only available on training data)\n",
    "    Survived    - Survived  (0 = No; 1 = Yes)\n",
    "    Pclass      - Passenger Class  (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "    Name        - Name\n",
    "    Sex         - Sex\n",
    "    Age         - Age\n",
    "    Sibsp       - Number of Siblings/Spouses Aboard\n",
    "    Parch       - Number of Parents/Children Aboard\n",
    "    Ticket      - Ticket Number\n",
    "    Fare        - Passenger Fare (British pound)\n",
    "    Cabin       - Cabin code\n",
    "    Embarked    - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "    \n",
    "    Arguments:\n",
    "    df -- Dataset, Pandas DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    df -- Dataset, Pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Age has missing values which is replaced with average\n",
    "    # Might also consider dividing age into classes of age brackets\n",
    "    df['Age'].fillna((df['Age'].mean()), inplace = True)\n",
    "    df['Fare'].fillna((df['Fare'].mean()), inplace = True)\n",
    "    \n",
    "    # Encode sex into binary (0 = male, 1 = female)\n",
    "    df['Sex'] = df['Sex'].map({'female': 1, 'male': 0})\n",
    "    \n",
    "    # Turning Cabin number into Deck\n",
    "    cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    df['Deck' ]= df['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    \n",
    "    # Calculate family size\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    \n",
    "    # Age brackets\n",
    "    df['AgeBracket'] = df['Age'].apply(lambda x: 'Child' if x <= 10 else ('Adult' if x < 50 else 'Senior'))\n",
    "\n",
    "    # Extract and process titles\n",
    "    df['Title']= df['Name'].map(lambda x: extract_title(x))\n",
    "    if not prediction_data:\n",
    "        unique_titles = df['Title'].unique()\n",
    "        survival_by_title = df.groupby('Title').mean()['Survived']\n",
    "        \n",
    "    df['Title']=df.apply(simplify_titles, axis=1)\n",
    "    if not prediction_data:\n",
    "        unique_titles_simplified = df['Title'].unique()\n",
    "        survival_by_title_simplified = df.groupby('Title').mean()['Survived']\n",
    "    \n",
    "\n",
    "    # Gather info on the significance of these classes for survival\n",
    "    # Class was, as expected, significance for surival with the rates (1st - 63%, 2nd - 47%, 3rd - 24%)\n",
    "    # Embarked was suprisingly significant, C - Cherbourg had 55% surivial rate when the mean was just 38%\n",
    "    if not prediction_data:\n",
    "        survival_by_plcass = df.groupby('Pclass').mean()['Survived']\n",
    "        survival_by_deck = df.groupby('Deck').mean()['Survived']\n",
    "        survival_by_embark = df.groupby('Embarked').mean()['Survived']\n",
    "        survival_by_familysize = df.groupby('FamilySize').mean()['Survived']\n",
    "        survival_by_agebracket = df.groupby('AgeBracket').mean()['Survived']\n",
    "    \n",
    "    # Split classes with one hot encoding\n",
    "    # Pclass   - splits into (1 = Pclass_1, 2 = Pclass_2, 3 = Pclass_3)\n",
    "    # Embarked - splits into (C = Embarked_C, Q = Embarked_Q, S = Embarked_S)\n",
    "    # Deck - splits into decks with letters\n",
    "    df = pd.get_dummies(df, columns = ['Pclass', 'Embarked', 'Deck', 'AgeBracket', 'Title'])\n",
    "\n",
    "    # Drop columns with data deemed not relevant for learning\n",
    "    # Name     - Gender already has its' own column. Only thing that might be interesting here is the title\n",
    "    # Ticket   - Ticket does not really say much, price and class are already included which says the most\n",
    "    # Cabin    - Replaced by Deck\n",
    "    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Age'], axis=1) #, 'SibSp', 'Parch'], axis=1)\n",
    "    \n",
    "    if prediction_data:\n",
    "        m = df.shape[0]\n",
    "        df['Deck_T'] = pd.Series(np.zeros(m, dtype=int), index=df.index)\n",
    "    \n",
    "    # Normalize the data\n",
    "    norm_vals = ['Fare', 'FamilySize', 'SibSp', 'Parch'] #, 'Age']\n",
    "    df[norm_vals] = (df[norm_vals] - df[norm_vals].min())/(df[norm_vals].max() - df[norm_vals].min())\n",
    "    \n",
    "    if print_info:\n",
    "        if not prediction_data:\n",
    "            print('--------------------------------------------------------------------------------------')\n",
    "            print('SURVIVAL RATE')\n",
    "            print('--------------------------------------------------------------------------------------')\n",
    "            print('Overall survival rate: ' + str(df['Survived'].mean()))\n",
    "            print()\n",
    "            print(survival_by_plcass)\n",
    "            print()\n",
    "            print(survival_by_embark)\n",
    "            print()\n",
    "            print(survival_by_deck)\n",
    "            print()\n",
    "            print(survival_by_title)\n",
    "            print()\n",
    "            print(survival_by_title_simplified)\n",
    "            print()\n",
    "            print(survival_by_familysize)\n",
    "            print()\n",
    "            print(survival_by_agebracket)      \n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('TITLES')\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('All titels: ')\n",
    "        print(unique_titles)\n",
    "        print()\n",
    "        print('Simplied titels: ')\n",
    "        print(unique_titles_simplified)\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('SUMS')\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print(df.sum())\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('DATA INFO')\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print(df.info())\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('MISSING VALUES')\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print(df.isnull().sum())\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print('CORRELATIONS')\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "        print(df.corr())\n",
    "        print('--------------------------------------------------------------------------------------')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Splits the data into test/training set for simple validation\n",
    "\n",
    "    Arguments:\n",
    "    df -- Dataset, pandas dataframe\n",
    "        \n",
    "    Returns:\n",
    "    train -- Training samples, pandas dataframe\n",
    "    test -- Test samples, pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    df_train = df.sample(frac = 0.8, random_state = 42)\n",
    "    df_test = df.drop(df_train.index)  \n",
    "    \n",
    "    X_train = df_train.drop(['Survived'], axis=1).values\n",
    "    y_train = df_train['Survived'].values\n",
    "    \n",
    "    X_test = df_test.drop(['Survived'], axis=1).values\n",
    "    y_test = df_test['Survived'].values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (713, 27)\n",
      "y_train shape: (713,)\n",
      "X_test shape: (178, 27)\n",
      "y_test shape: (178,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_T</th>\n",
       "      <th>Deck_Unknown</th>\n",
       "      <th>AgeBracket_Adult</th>\n",
       "      <th>AgeBracket_Child</th>\n",
       "      <th>AgeBracket_Senior</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex  SibSp  Parch      Fare  FamilySize  Pclass_1  Pclass_2  \\\n",
       "0         0    0  0.125    0.0  0.014151         0.1         0         0   \n",
       "1         1    1  0.125    0.0  0.139136         0.1         1         0   \n",
       "2         1    1  0.000    0.0  0.015469         0.0         0         0   \n",
       "3         1    1  0.125    0.0  0.103644         0.1         1         0   \n",
       "4         0    0  0.000    0.0  0.015713         0.0         0         0   \n",
       "\n",
       "   Pclass_3  Embarked_C    ...      Deck_G  Deck_T  Deck_Unknown  \\\n",
       "0         1           0    ...           0       0             1   \n",
       "1         0           1    ...           0       0             0   \n",
       "2         1           0    ...           0       0             1   \n",
       "3         0           0    ...           0       0             0   \n",
       "4         1           0    ...           0       0             1   \n",
       "\n",
       "   AgeBracket_Adult  AgeBracket_Child  AgeBracket_Senior  Title_Master  \\\n",
       "0                 1                 0                  0             0   \n",
       "1                 1                 0                  0             0   \n",
       "2                 1                 0                  0             0   \n",
       "3                 1                 0                  0             0   \n",
       "4                 1                 0                  0             0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  \n",
       "0           0         1          0  \n",
       "1           0         0          1  \n",
       "2           1         0          0  \n",
       "3           0         0          1  \n",
       "4           0         1          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = preprocess_dataframe(df, False, False)\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_data(df_processed)\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))\n",
    "\n",
    "df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a decision tree classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    dt_clf -- Classifier, sklearn DecisionTreeClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    dt_clf = sk.tree.DecisionTreeClassifier(max_depth=20)\n",
    "    dt_clf.fit (X_train, y_train)\n",
    "    print(dt_clf.score (X_test, y_test))\n",
    "    \n",
    "    return dt_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8089887640449438\n"
     ]
    }
   ],
   "source": [
    "dt_clf = decision_tree_clf(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a random forest classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    rf_clf -- Classifier, sklearn RandomForestClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    rf_clf = ske.RandomForestClassifier(n_estimators=50)\n",
    "    rf_clf.fit (X_train, y_train)\n",
    "    print(rf_clf.score (X_test, y_test))\n",
    "    \n",
    "    return rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "rf_clf = random_forest_clf(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_boosting_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a gradient boosting classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    gb_clf -- Classifier, sklearn GradiantBoostingClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    gb_clf = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "    gb_clf.fit (X_train, y_train)\n",
    "    print(gb_clf.score (X_test, y_test))\n",
    "    \n",
    "    return gb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848314606741573\n"
     ]
    }
   ],
   "source": [
    "gb_clf = gradient_boosting_clf(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a logistic regression classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    rf_clf -- Classifier, sklearn LogisticRegression\n",
    "    \"\"\"\n",
    "    \n",
    "    lr_clf = LogisticRegression()\n",
    "    lr_clf.fit (X_train, y_train)\n",
    "    print(lr_clf.score (X_test, y_test))\n",
    "    \n",
    "    return lr_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8370786516853933\n"
     ]
    }
   ],
   "source": [
    "lr_clf = logistic_regression_clf(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def support_vector_machine_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a support vector machine classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    svm_clf -- Classifier, sklearn SVC\n",
    "    \"\"\"\n",
    "    \n",
    "    svm_clf = sk.svm.SVC(probability=True)\n",
    "    svm_clf.fit (X_train, y_train)\n",
    "    print(svm_clf.score (X_test, y_test))\n",
    "    \n",
    "    return svm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258426966292135\n"
     ]
    }
   ],
   "source": [
    "svm_clf = support_vector_machine_clf(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_bayes_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a gaussian naive bayes classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    svm_clf -- Classifier, sklearn GaussianNB\n",
    "    \"\"\"\n",
    "    \n",
    "    nb_clf = GaussianNB()\n",
    "    nb_clf.fit (X_train, y_train)\n",
    "    print(nb_clf.score (X_test, y_test))\n",
    "    \n",
    "    return nb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7247191011235955\n"
     ]
    }
   ],
   "source": [
    "nb_clf = naive_bayes_clf(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_neighbors_clf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains a k-nearest neighbors classifier\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- Training features,numpy matrix (m, 11)\n",
    "    y_train -- Training features,numpy matrix (m, )\n",
    "    X_test -- Test features,numpy matrix (m, 11)\n",
    "    y_test -- Test features,numpy matrix (m, )\n",
    "        \n",
    "    Returns:\n",
    "    svm_clf -- Classifier, sklearn KNeighborsClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=6)\n",
    "    knn_clf.fit (X_train, y_train)\n",
    "    print(knn_clf.score (X_test, y_test))\n",
    "    \n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146067415730337\n"
     ]
    }
   ],
   "source": [
    "knn_clf = k_neighbors_clf(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensamble_voting_clf(clfs, X_train, y_train, X_test, y_test, cv=20, score_individually=False):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Builds and trains an ensamble of classifiers which them vote together\n",
    "\n",
    "    Arguments:\n",
    "    clfs -- Classifiers with labels, List Tuple(String, clf)\n",
    "    \n",
    "    Returns:\n",
    "    e_clf -- Classifier, sklearn VotingClassifier\n",
    "    \"\"\"\n",
    "    \n",
    "    e_clf = ske.VotingClassifier(estimators=clfs, voting='hard') # Hard voting where majority rules\n",
    "    e_clf.fit (X_train, y_train)\n",
    "    \n",
    "    if score_individually:\n",
    "        for label, clf in clfs:\n",
    "            scores = cross_val_score(clf, X_test, y_test, cv=cv, scoring='accuracy')\n",
    "            print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))    \n",
    "    \n",
    "    scores = cross_val_score(e_clf, X_test, y_test, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), 'Voting Ensamble')) \n",
    "    \n",
    "    return e_clf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 (+/- 0.11) [Decision Tree]\n",
      "Accuracy: 0.83 (+/- 0.09) [Random Forest]\n",
      "Accuracy: 0.83 (+/- 0.11) [Gradiant Boosting]\n",
      "Accuracy: 0.84 (+/- 0.11) [Logistic Regression]\n",
      "Accuracy: 0.81 (+/- 0.10) [SVM]\n",
      "Accuracy: 0.70 (+/- 0.17) [Naive Bayes]\n",
      "Accuracy: 0.81 (+/- 0.11) [K-Nearest]\n",
      "Accuracy: 0.85 (+/- 0.09) [Voting Ensamble]\n"
     ]
    }
   ],
   "source": [
    "clfs = ([('Decision Tree', dt_clf), ('Random Forest', rf_clf), ('Gradiant Boosting', gb_clf), \n",
    "         ('Logistic Regression', lr_clf), ('SVM', svm_clf), ('Naive Bayes', nb_clf), ('K-Nearest', knn_clf)])\n",
    "\n",
    "e_clf = ensamble_voting_clf(clfs, X_train, y_train, X_test, y_test, score_individually=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(df, clf, export_path):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    Makes predictions X -> y and exports to csv\n",
    "\n",
    "    Arguments:\n",
    "    df -- Data to predict from, pandas DataFrame\n",
    "    clf -- classifier, Classifier, sklearn classifier object\n",
    "    export_path -- Path and name of file, String\n",
    "        \n",
    "    Returns:\n",
    "    df_pred -- prediction, pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract Ids\n",
    "    y1 = df['PassengerId'].values\n",
    "    \n",
    "    # Make predictions\n",
    "    df_process = preprocess_dataframe(df, prediction_data=True, print_info=False) \n",
    "    X = df_process.values\n",
    "    y2 = clf.predict(X)\n",
    "    \n",
    "    # Combine ids and predictions\n",
    "    y = np.column_stack((y1, y2))\n",
    "    \n",
    "    # Restore pandas df\n",
    "    df_pred = pd.DataFrame(y)\n",
    "    df_pred.columns = [\"PassengerId\", \"Survived\"]\n",
    "    \n",
    "    # Export\n",
    "    df_pred.to_csv(export_path, sep=',', index=False)\n",
    "    \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         1\n",
       "1          893         0\n",
       "2          894         1\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('C:/GitHub/kaggle/titanic/data/test.csv', sep=',', header=0)\n",
    "df_pred = predict(df_pred, rf_clf, 'C:/GitHub/kaggle/titanic/predictions/predictions_random_forest.csv')\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report(results, n_top=1):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_search_hyperparameters(clf, hyper_param, X_train, y_train, X_test, y_test, print_result=False):\n",
    "    \n",
    "    # run randomized search\n",
    "    n_iter_search = 10\n",
    "    rnd_clf = RandomizedSearchCV(clf, param_distributions=hyper_param, n_iter=n_iter_search)\n",
    "\n",
    "    start = time()\n",
    "    rnd_clf.fit(X_train, y_train)\n",
    "    \n",
    "    if print_result:\n",
    "        print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "              \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "        report(rnd_clf.cv_results_)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        scores = cross_val_score(clf, X_test, y_test, cv=20, scoring='accuracy')\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "        print()\n",
    "        print(classification_report(y_true, y_pred))\n",
    "       \n",
    "    return rnd_clf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_hyperparameters(clf, hyper_param, X_train, y_train, X_test, y_test, print_result=False):\n",
    "    \n",
    "    # run grid search\n",
    "    grid_clf = GridSearchCV(clf, param_grid=hyper_param)\n",
    "    start = time()\n",
    "    grid_clf.fit(X_train, y_train)\n",
    "    \n",
    "    if print_result:\n",
    "        report(grid_clf.cv_results_)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        scores = cross_val_score(clf, X_test, y_test, cv=20, scoring='accuracy')\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "        print()\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    return grid_clf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "hyper_param = {\"max_depth\": [3, None],\n",
    "               \"max_features\": stats.randint(3, X_train.shape[1]),\n",
    "               \"min_samples_split\": stats.randint(2, 11),\n",
    "               \"min_samples_leaf\": stats.randint(1, 11),\n",
    "               \"bootstrap\": [True, False],\n",
    "               \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rnd_rf_clf = random_search_hyperparameters(rf_clf, hyper_param, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.833 (std: 0.012)\n",
      "Parameters: {'min_samples_leaf': 10, 'bootstrap': True, 'criterion': 'gini', 'max_features': 10, 'min_samples_split': 2, 'max_depth': None}\n",
      "\n",
      "Accuracy: 0.80 (+/- 0.10)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86       113\n",
      "          1       0.75      0.75      0.75        65\n",
      "\n",
      "avg / total       0.82      0.82      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "hyper_param = {\"max_depth\": [3, None],\n",
    "               \"max_features\": [3, 10, X_train.shape[1]],\n",
    "               \"min_samples_split\": [2, 3, 10],\n",
    "               \"min_samples_leaf\": [1, 3, 10],\n",
    "               \"bootstrap\": [True, False],\n",
    "               \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rf_grid_clf = grid_search_hyperparameters(rf_clf, hyper_param, X_train, y_train, X_test, y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "hyper_param = {'C': stats.randint(10, 10000),\n",
    "               'gamma' : stats.uniform(0.001, 1),\n",
    "               'kernel': ['rbf']}\n",
    "\n",
    "svm_rnd_clf = random_search_hyperparameters(svm_clf, hyper_param, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.822 (std: 0.018)\n",
      "Parameters: {'C': 10, 'kernel': 'rbf', 'gamma': 0.1}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.822 (std: 0.006)\n",
      "Parameters: {'C': 10000, 'kernel': 'rbf', 'gamma': 0.001}\n",
      "\n",
      "Accuracy: 0.81 (+/- 0.10)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.87      0.86       113\n",
      "          1       0.77      0.75      0.76        65\n",
      "\n",
      "avg / total       0.83      0.83      0.83       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "hyper_param = {'C': [10, 100, 1000, 10000], \n",
    "               'gamma' : [0.001, 0.01, 0.1, 1], \n",
    "               'kernel': ['rbf']}\n",
    "\n",
    "svm_grid_clf = grid_search_hyperparameters(svm_clf, hyper_param, X_train, y_train, X_test, y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "hyper_param = {'penalty': ['l1','l2'], \n",
    "               'C': stats.uniform(0.001,1000)}\n",
    "\n",
    "lr_rnd_clf = random_search_hyperparameters(lr_clf, hyper_param, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.818 (std: 0.007)\n",
      "Parameters: {'penalty': 'l2', 'C': 10}\n",
      "\n",
      "Accuracy: 0.84 (+/- 0.11)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.87       113\n",
      "          1       0.77      0.78      0.78        65\n",
      "\n",
      "avg / total       0.84      0.84      0.84       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use a full grid over all parameters\n",
    "hyper_param = {'penalty': ['l1','l2'], \n",
    "               'C': [0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "lr_grid_clf = grid_search_hyperparameters(lr_clf, hyper_param, X_train, y_train, X_test, y_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.06) [Voting Ensamble]\n"
     ]
    }
   ],
   "source": [
    "clfs = ([('Grid Random Forest', rf_grid_clf), ('Grid SVM', svm_grid_clf), ('Grid Logistic Regression', lr_grid_clf)])\n",
    "\n",
    "e_grid_clf = ensamble_voting_clf(clfs, X_train, y_train, X_test, y_test, score_individually=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         1\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('C:/GitHub/kaggle/titanic/data/test.csv', sep=',', header=0)\n",
    "df_pred = predict(df_pred, lr_grid_clf, 'C:/GitHub/kaggle/titanic/predictions/predictions_tuned_logistic_regression.csv')\n",
    "df_pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(paramters):\n",
    "    \n",
    "    num_features = parameters['num_features']\n",
    "    X = tf.placeholder(tf.float32, [None, num_features], name='X')\n",
    "    y = tf.placeholder(tf.float32, [None, 1], name='y')\n",
    "\n",
    "    layers_dim = paramters['layers_dim']\n",
    "    \n",
    "    fc = tf.contrib.layers.stack(X, tf.contrib.layers.fully_connected, layers_dim)\n",
    "    Z = tf.contrib.layers.fully_connected(fc, 1, activation_fn=None, scope='Z')\n",
    "    \n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z, labels=y, name='Loss')\n",
    "    cost = tf.reduce_mean(loss, name='Cost')\n",
    "    \n",
    "    learning_rate = parameters['learning_rate']\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    prediction = tf.round(tf.sigmoid(Z))\n",
    "    correct_prediction = tf.equal(prediction, y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    model = {'X': X, 'y': y, 'Z': Z, 'cost': cost,\n",
    "             'train_op': train_op, 'prediction': prediction, 'accuracy': accuracy}\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X_train, Y_train, mini_batch_size = 32, seed = 0):\n",
    " \n",
    "    # Shuffle with identical seed to get same shuffle in both X and Y\n",
    "    np.random.seed(seed)\n",
    "    X_train = np.random.permutation(X_train)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    Y_train = np.random.permutation(Y_train)\n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "    num_batches = int(m / mini_batch_size)\n",
    "    \n",
    "    # Split data into smaller batches for ready for stochastic gradient descent\n",
    "    minibatches_X = np.array_split(X_train, num_batches)\n",
    "    minibatches_Y = np.array_split(Y_train, num_batches)\n",
    "    \n",
    "    minibatches = zip(minibatches_X, minibatches_Y)\n",
    "    \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(parameters, model):\n",
    "    \n",
    "    num_epochs = parameters['num_epochs']\n",
    "    minibatch_size = parameters['minibatch_size']\n",
    "    X_train = parameters['X_train']\n",
    "    y_train = parameters['y_train']\n",
    "    \n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    saver = tf.train.Saver()\n",
    "    epoch_list = []\n",
    "    cost_list = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            epoch_cost = 0.\n",
    "            num_minibatches = int(train_size / minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "                \n",
    "                (minibatch_X, minibatch_y) = minibatch\n",
    "                minibatch_y = np.reshape(minibatch_y, (minibatch_X.shape[0], 1))\n",
    "                feed_dict = {model['X'] : minibatch_X, model['y'] : minibatch_y}\n",
    "\n",
    "                _model ,minibatch_cost = sess.run([model['train_op'], model['cost']], feed_dict= feed_dict)\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            \n",
    "            if parameters['print'] and (epoch % parameters['print_freq'] == 0):\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            \n",
    "            if parameters['save_cost'] and (epoch % parameters['save_cost_freq'] == 0):\n",
    "                epoch_list.append(epoch)\n",
    "                cost_list.append(epoch_cost)\n",
    "                \n",
    "        saver.save(sess, parameters['save_path'])\n",
    "        \n",
    "    return {'epoch_list': epoch_list, 'cost_list' : cost_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "\n",
    "# set model parameters\n",
    "parameters['X_train'] = X_train\n",
    "parameters['y_train'] = y_train\n",
    "parameters['X_test'] = X_test\n",
    "parameters['y_test'] = y_test\n",
    "parameters['layers_dim'] = [14]\n",
    "parameters['num_features'] = X_train.shape[1]\n",
    "parameters['layers_dim'] = [14]\n",
    "parameters['learning_rate'] = 0.01\n",
    "\n",
    "# set train parameters (hyper parameter)\n",
    "parameters['num_epochs'] = 3000\n",
    "parameters['minibatch_size'] = 20\n",
    "\n",
    "# set option parameters\n",
    "parameters['model_name'] = 'nn_clf'\n",
    "parameters['save_path'] = 'C:/GitHub/kaggle/titanic/models/' + parameters['model_name']\n",
    "parameters['print'] = True\n",
    "parameters['print_freq'] = 500\n",
    "parameters['save_cost'] = True\n",
    "parameters['save_cost_freq'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.556942\n",
      "Cost after epoch 500: 0.302037\n",
      "Cost after epoch 1000: 0.297273\n",
      "Cost after epoch 1500: 0.293644\n",
      "Cost after epoch 2000: 0.292970\n",
      "Cost after epoch 2500: 0.290712\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = create_model(parameters)\n",
    "    plot_data = train_model(parameters, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x236730e2278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print\n",
    "if parameters['save_cost']:\n",
    "    plt.plot(plot_data['epoch_list'], plot_data['cost_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(parameters, model):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess, parameters['save_path'])\n",
    "        print (\"Train Accuracy:\", model['accuracy'].eval({model['X']: X_train, \n",
    "                                                          model['y']: np.reshape(y_train, (X_train.shape[0], 1)) }))\n",
    "        print (\"Valid Accuracy:\", model['accuracy'].eval({model['X']: X_test, \n",
    "                                                          model['y']: np.reshape(y_test, (X_test.shape[0], 1)) }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/GitHub/kaggle/titanic/models/nn_clf\n",
      "Train Accuracy: 0.87798035\n",
      "Valid Accuracy: 0.8258427\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    model = create_model(parameters)\n",
    "    evaluate(parameters, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_nn(parameters, model):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        saver.restore(sess, parameters['model_name']) \n",
    "        return model['prediction'].eval({model['X']: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer = pd.DataFrame(test_df['PassengerId'], columns=['PassengerId'])\n",
    "with tf.Graph().as_default():\n",
    "    model = create_model(parameters)\n",
    "    y_pred = predict_nn(parameters, model)\n",
    "    answer['Survived'] = y_pred.astype(int)\n",
    "    \n",
    "    # Extract Ids\n",
    "    y1 = df['PassengerId'].values\n",
    "    \n",
    "    # Make predictions\n",
    "    df_process = preprocess_dataframe(df, prediction_data=True, print_info=False) \n",
    "    X = df_process.values\n",
    "    y2 = clf.predict(X)\n",
    "    \n",
    "    # Combine ids and predictions\n",
    "    y = np.column_stack((y1, y2))\n",
    "    \n",
    "    # Restore pandas df\n",
    "    df_pred = pd.DataFrame(y)\n",
    "    df_pred.columns = [\"PassengerId\", \"Survived\"]\n",
    "    \n",
    "    # Export\n",
    "    df_pred.to_csv(export_path, sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
