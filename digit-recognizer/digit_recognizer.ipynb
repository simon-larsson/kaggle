{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/GitHub/kaggle/digit-recognizer/data/train.csv', sep=',', header=0)\n",
    "print(df.info())\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "\n",
    "    train=df.sample(frac=0.8,random_state=42)\n",
    "    val=df.drop(train.index)\n",
    "    \n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_val = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def restore_dimensions(df, prediction=False):   \n",
    "    \n",
    "    X = df.loc[:, 'pixel0':'pixel783']\n",
    "    X = X.values \n",
    "    m = X.shape[0]   \n",
    "    X = np.reshape(X, (m, 28, 28, 1))\n",
    "    \n",
    "    if prediction:\n",
    "        Y = None\n",
    "    else:\n",
    "        y = df.loc[:, 'label']\n",
    "        Y = pd.get_dummies(y, columns = ['label'])\n",
    "        Y  = Y.values\n",
    "        Y = np.reshape(Y, (m, 10))\n",
    "            \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 33600\n",
      "Number of validation examples = 8400\n",
      "X_train shape: (33600, 28, 28, 1)\n",
      "Y_train shape: (33600, 10)\n",
      "X_val shape: (8400, 28, 28, 1)\n",
      "Y_val shape: (8400, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = restore_dimensions(df_train)\n",
    "X_val, Y_val = restore_dimensions(df_val)\n",
    "\n",
    "print (\"Number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"Number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_H0, n_W0, n_C0), name='X')\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y), name='Y')\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_1:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "Y = Tensor(\"Y_1:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "n_H = X_train.shape[1]\n",
    "n_W = X_train.shape[2]\n",
    "n_C = 1\n",
    "n_y = Y_train.shape[1]\n",
    "\n",
    "X, Y = create_placeholders(n_H, n_W, n_C, n_y)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  \n",
    "    # Init variables with xavier initializers - prevents weights from being too small/big\n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, 1, 8], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "W1 = [[-0.1580479  -0.16130143 -0.14990367 -0.18879274  0.00317255  0.04239197\n",
      "   0.19033411 -0.14808246]]\n",
      "W2 = [ 0.05945182 -0.24659145 -0.23628843  0.19142652 -0.01223731  0.03257239\n",
      "  0.00916171 -0.17187983  0.04244643 -0.10146749 -0.10593873  0.044186\n",
      " -0.06422544  0.05488336  0.05805546  0.19174701]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess_test:\n",
    "    parameters = initialize_parameters()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess_test.run(init)\n",
    "    \n",
    "    print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME', name='Z1')\n",
    "    \n",
    "    # RELU\n",
    "    A1 = tf.nn.relu(Z1, name='A1')\n",
    "    \n",
    "    # MAXPOOL: window 4x4, sride 2, padding 'SAME'\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME', name='P1')\n",
    "    \n",
    "    # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME', name='Z2')\n",
    "    \n",
    "    # RELU\n",
    "    A2 = tf.nn.relu(Z2, name='A2')\n",
    "    \n",
    "    # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME', name='P2')\n",
    "    \n",
    "    # FLATTEN\n",
    "    P2 = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    # FULLY-CONNECTED: 40 units, RelU activation\n",
    "    Z3 = tf.contrib.layers.fully_connected(P2, 40, activation_fn=tf.nn.relu, scope='Z3')\n",
    "    \n",
    "    # FULLY-CONNECTED-OUTPUT: 10 units, no activation (is in cost function)\n",
    "    Z4 = tf.contrib.layers.fully_connected(Z3, 10, activation_fn=None, scope='Z4')\n",
    "\n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = [[-0.69819105  0.44099775 -1.7828609   1.2550921  -0.36044133 -0.86019313\n",
      "  -0.9017037   0.05264278  0.1788131  -0.2635119 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y= X, Y = create_placeholders(n_H, n_W, n_C, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(Z, {X: np.random.randn(1,n_H,n_W,n_C), Y: np.random.randn(1,n_y)})\n",
    "    print(\"Z = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z, Y):\n",
    "    \n",
    "     # Define a sigmoid based discrete classifier as a loss function\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z, labels=Y, name='loss')\n",
    "    \n",
    "    # Define a function to measure cost\n",
    "    cost = tf.reduce_mean(loss, name='cost')\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = -0.434353\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(n_H, n_W, n_C, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, feed_dict={X: np.random.randn(100, n_H, n_W, n_C), Y: np.random.randn(100, n_y)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "\n",
    "    # Shuffle with identical seed to get same shuffle in both X and Y\n",
    "    np.random.seed(seed)\n",
    "    X_train = np.random.permutation(X_train)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    Y_train = np.random.permutation(Y_train)\n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "    num_minibatches = int(m / minibatch_size)\n",
    "    \n",
    "    # Split data into smaller batches for ready for stochastic gradient descent\n",
    "    minibatches_X = np.array_split(X_train, num_minibatches)\n",
    "    minibatches_Y = np.array_split(Y_train, num_minibatches)\n",
    "    \n",
    "    minibatches = zip(minibatches_X, minibatches_Y)\n",
    "    \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_val, Y_val, learning_rate = 0.009, num_epochs = 100, \n",
    "          minibatch_size = 32, print_cost = True, save_path = './'):\n",
    "    \n",
    "    ops.reset_default_graph()                      \n",
    "    tf.set_random_seed(42)                            \n",
    "    seed = 42                                         \n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape  \n",
    "    n_y = Y_val.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #Create a saver object which will save all the variables\n",
    "    saver = tf.train.Saver()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        val_accuracy = accuracy.eval({X: X_val, Y: Y_val})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Validation Accuracy:\", val_accuracy)\n",
    "        \n",
    "        #Save the graph\n",
    "        saver.save(sess, save_path)\n",
    "                \n",
    "        return val_accuracy, val_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.166293\n",
      "Cost after epoch 5: 0.152251\n",
      "Cost after epoch 10: 0.129642\n",
      "Cost after epoch 15: 0.129652\n",
      "Cost after epoch 20: 0.125055\n",
      "Cost after epoch 25: 0.123699\n",
      "Cost after epoch 30: 0.123392\n",
      "Cost after epoch 35: 0.125963\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsNFFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262e2bb9c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.9719345\n",
      "Validation Accuracy: 0.9628571\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, \n",
    "                         Y_train, \n",
    "                         X_val, \n",
    "                         Y_val,\n",
    "                         learning_rate = 0.003,\n",
    "                         num_epochs=40, \n",
    "                         save_path='C:/GitHub/kaggle/digit-recognizer/models/digit_recognizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
